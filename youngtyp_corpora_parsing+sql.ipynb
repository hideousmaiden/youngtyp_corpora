{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hideousmaiden/youngtyp_corpora/blob/sasha/youngtyp_corpora_parsing%2Bsql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KDUCQ5jEpgNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2e084a-5412-4103-b23c-1db9bc8da089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import re\n",
        "import sqlite3\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('youngtyp.db')\n",
        "cur = conn.cursor()"
      ],
      "metadata": {
        "id": "wLimCZ3ap9pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаю пустую базу\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS texts\n",
        "(id_text int, text text)\n",
        "\"\"\")\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS meta\n",
        "(id_text int, author text, topic text, year int, affilation text) \n",
        "\"\"\")\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS sents \n",
        "(id_text int, id_sent int, sent text) \n",
        "\"\"\")\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS words\n",
        "(id_text int, id_sent int, id_word int, word text collate nocase, lemma text, pos text)\n",
        "\"\"\")\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS words_right\n",
        "(id_text int, id_sent int, id_word_right int, word_right text collate nocase, lemma_right text, pos_right text)\n",
        "\"\"\")\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS words_rright\n",
        "(id_text int, id_sent int, id_word_rright int, word_rright text collate nocase, lemma_rright text, pos_rright text)\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "conn.commit()  # создаю базу"
      ],
      "metadata": {
        "id": "l_JEILQyqHTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -r 'https://raw.githubusercontent.com/hideousmaiden/youngtyp_corpora/sasha/theses.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dm3KngMIVYF",
        "outputId": "d69974d8-ab84-45b0-fb05-aed88c52a70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-24 09:48:10--  https://raw.githubusercontent.com/hideousmaiden/youngtyp_corpora/sasha/theses.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3733358 (3.6M) [text/plain]\n",
            "Saving to: ‘raw.githubusercontent.com/hideousmaiden/youngtyp_corpora/sasha/theses.json’\n",
            "\n",
            "raw.githubuserconte 100%[===================>]   3.56M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-10-24 09:48:10 (42.6 MB/s) - ‘raw.githubusercontent.com/hideousmaiden/youngtyp_corpora/sasha/theses.json’ saved [3733358/3733358]\n",
            "\n",
            "FINISHED --2022-10-24 09:48:10--\n",
            "Total wall clock time: 0.6s\n",
            "Downloaded: 1 files, 3.6M in 0.08s (42.6 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('raw.githubusercontent.com/hideousmaiden/youngtyp_corpora/sasha/theses.json', 'r', encoding=\"utf-8\") as f:\n",
        "  bodies = json.load(f)"
      ],
      "metadata": {
        "id": "GPx4QlNYKkHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writing down raw text and sentences\n",
        "for id, t_id in enumerate(bodies.keys()):\n",
        "    cur.execute(\"\"\"INSERT INTO texts\n",
        "                (id_text, text) \n",
        "                VALUES (?, ?)\"\"\", (id, bodies[t_id]['text']))\n",
        "    cur.execute(\"\"\"INSERT INTO meta\n",
        "                (id_text, author, topic, year, affilation) \n",
        "                VALUES (?, ?, ?, ?, ?)\"\"\", (id,\n",
        "                                         bodies[t_id]['author'], bodies[t_id]['title'],\n",
        "                                         bodies[t_id]['year'], bodies[t_id]['affilation']))\n",
        "    sents = sent_tokenize(bodies[t_id]['text'])\n",
        "    for spair in enumerate(sents):\n",
        "      cur.execute(\"\"\"INSERT INTO sents\n",
        "                (id_text, id_sent, sent) \n",
        "                VALUES (?, ?, ?)\"\"\", (id, *spair))\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "nNp-xzERv6Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iU2sfln5LwBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Парсинг"
      ],
      "metadata": {
        "id": "LJ_KTw4gzUhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install deeppavlov"
      ],
      "metadata": {
        "id": "_vOhU1OczX40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deeppavlov\n",
        "#!python -m deeppavlov install morpho_ru_syntagrus_pymorphy"
      ],
      "metadata": {
        "id": "ZvxhvlrRzbsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "#model = build_model(configs.morpho_tagger.UD2_0.morpho_ru_syntagrus_pymorphy, download=True)"
      ],
      "metadata": {
        "id": "BRcXD6Rzz3MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "QEKR5KFG3k8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writing down words\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "    SELECT id_text, id_sent, sent\n",
        "    FROM sents\"\"\")\n",
        "sents = cur.fetchall()\n",
        "for one in sents:\n",
        "#    tags = list(filter(lambda x: len(x)>2, tags))\n",
        "    words = word_tokenize(one[-1])\n",
        "    words=[word for word in words if word.isalpha()]\n",
        "    if len(words) == 0:\n",
        "      continue\n",
        "    tags = model(words)\n",
        "    pos = list(map(lambda x: re.split('\\t',x)[2] if len(x)>2 else x, tags))\n",
        "    lems = list(map(lambda x: morph.parse(x)[0].normal_form, words))\n",
        "    for wrd in zip(range(len(pos)), words, lems, pos):\n",
        "        cur.execute(\"\"\"INSERT INTO words\n",
        "                (id_text, id_sent, id_word, word, lemma, pos) \n",
        "                VALUES (?, ?, ?, ?, ?, ?)\"\"\", (one[0], one[1], *wrd))\n",
        "        cur.execute(\"\"\"INSERT INTO words_right\n",
        "                (id_text, id_sent, id_word_right, word_right, lemma_right, pos_right) \n",
        "                VALUES (?, ?, ?, ?, ?, ?)\"\"\", (one[0], one[1], *wrd))\n",
        "        cur.execute(\"\"\"INSERT INTO words_rright\n",
        "                (id_text, id_sent, id_word_rright, word_rright, lemma_rright, pos_rright) \n",
        "                VALUES (?, ?, ?, ?, ?, ?)\"\"\", (one[0], one[1], *wrd))\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "YvXuvOB-5cWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как в задании эксплицитно указано, что в поиске будет до трёх слов, поиск нам показалось удобным осуществлять по таблице, где для каждого слова в отдельных колонках указаны его правые соседи и их свойства.\n",
        "\n",
        "\n",
        "\n",
        "> беда: SQL не может быть case-insensitive для русского"
      ],
      "metadata": {
        "id": "2P7O71DEdFHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query(query, limit=10):\n",
        "  \"\"\"\n",
        "  process cql query\n",
        "\n",
        "  args:\n",
        "    query: str,\n",
        "  returns:\n",
        "    result: list of dict, list of dictionaries containing found results\n",
        "      pattern: str, found pattern\n",
        "      id_sent: int, \n",
        "      id_text: int,\n",
        "      id_word: int\n",
        "      (last_word_id: int)\n",
        "  \"\"\"\n",
        "# токены разделены словами\n",
        "  parts = query.split(' ')\n",
        "  # условия разделены плюсами\n",
        "  conds = list(map(lambda x: x.split('+'), parts))\n",
        "  pos_tr = {0:'pos',1:'pos_right', 2:'pos_rright'}\n",
        "  lemma_tr = {0:'lemma',1:'lemma_right', 2:'lemma_rright'}\n",
        "  word_tr = {0:'word',1:'word_right', 2:'word_rright'}\n",
        "  que = []\n",
        "  ask = {1:'''SELECT id_text, id_sent, id_word, word FROM big_words\n",
        "  WHERE {} COLLATE NOCASE\n",
        "  ORDER BY id_text ASC\n",
        "  LIMIT {};''', 2:'''SELECT id_text, id_sent, id_word, word, id_word_right, word_right FROM big_words\n",
        "  WHERE {} COLLATE NOCASE\n",
        "  ORDER BY id_text ASC\n",
        "  LIMIT {}\n",
        "  ;''', 3:'''SELECT id_text, id_sent, id_word, word, id_word_rright, word_rright FROM big_words\n",
        "  WHERE {} COLLATE NOCASE\n",
        "  ORDER BY id_text ASC\n",
        "  LIMIT {}'''}\n",
        "  # по словам\n",
        "  for nn, ques in enumerate(conds):\n",
        "    for cond in ques:\n",
        "      #все условия для одного слова\n",
        "      if re.match('[A-Z]+', cond):\n",
        "          \n",
        "          que.append('{} = \"{}\"'.format(pos_tr[nn], cond))\n",
        "      elif re.match(r'\".+\"', cond):\n",
        "          que.append('(({} = {}) '.format(word_tr[nn], cond) + 'OR ({} = {}) '.format(word_tr[nn], cond.lower()) + 'OR ({} = {}))'.format(word_tr[nn], cond.title()))\n",
        "          #que.append('{} = {}'.format(word_tr[nn], cond))\n",
        "      else:\n",
        "          que.append('{} = \"{}\"'.format(lemma_tr[nn], morph.parse(cond)[0].normal_form))\n",
        "  big_que = ' AND '.join(que)\n",
        "  ask = ask[len(conds)].format(big_que, limit)\n",
        "  cur.execute(ask)\n",
        "  done = set(cur.fetchall())\n",
        "  result = []\n",
        "  for res in list(done):\n",
        "    dd = dict()\n",
        "    dd['pattern'] = ' '.join(list(filter(lambda x: str(x).isalpha(), res)))\n",
        "    dd['id_sent'] = res[1]\n",
        "    dd['id_text'] = res[0]\n",
        "    dd['id_word'] = res[2]\n",
        "    if len(res) > 4:\n",
        "      dd['last_word_id'] = res[-2]\n",
        "    result.append(dd)\n",
        "  return result"
      ],
      "metadata": {
        "id": "nA3lTLaVi2El"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query_old(query, limit=10):\n",
        "  \"\"\"\n",
        "  process cql query\n",
        "\n",
        "  args:\n",
        "    query: str,\n",
        "  returns:\n",
        "    result: list of dict, list of dictionaries containing found results\n",
        "      pattern: str, found pattern\n",
        "      id_sent: int, \n",
        "      id_text: int,\n",
        "      id_word: int\n",
        "      (last_word_id: int)\n",
        "  \"\"\"\n",
        "# токены разделены словами\n",
        "  parts = query.split(' ')\n",
        "  # условия разделены плюсами\n",
        "  conds = list(map(lambda x: x.split('+'), parts))\n",
        "  pos_tr = {0:'pos',1:'pos_right', 2:'pos_rright'}\n",
        "  lemma_tr = {0:'lemma',1:'lemma_right', 2:'lemma_rright'}\n",
        "  word_tr = {0:'word',1:'word_right', 2:'word_rright'}\n",
        "  que = []\n",
        "  ask = {1:'''SELECT words.id_text, words.id_sent, words.id_word, words.word FROM words\n",
        "  JOIN words_right ON words_right.id_sent=words.id_sent AND words_right.id_text=words.id_text AND id_word_right = (id_word + 1)\n",
        "  JOIN words_rright ON words_rright.id_sent=words.id_sent AND words_rright.id_text=words.id_text AND id_word_rright = (id_word + 2)\n",
        "  WHERE {} COLLATE NOCASE\n",
        "  LIMIT {};''', 2:'''SELECT words.id_text, words.id_sent, words.id_word, words.word, id_word_right, word_right FROM words\n",
        "  JOIN words_right ON words_right.id_sent=words.id_sent AND words_right.id_text=words.id_text AND id_word_right = (id_word + 1)\n",
        "  JOIN words_rright ON words_rright.id_sent=words.id_sent AND words_rright.id_text=words.id_text AND id_word_rright = (id_word + 2)\n",
        "  WHERE {} COLLATE NOCASE\n",
        "  LIMIT {}\n",
        "  ;''', 3:'''SELECT words.id_text, words.id_sent, words.id_word, words.word, id_word_rright, word_rright FROM words\n",
        "  JOIN words_right ON words_right.id_sent=words.id_sent AND words_right.id_text=words.id_text AND id_word_right = (id_word + 1)\n",
        "  JOIN words_rright ON words_rright.id_sent=words.id_sent AND words_rright.id_text=words.id_text AND id_word_rright = (id_word + 2)\n",
        "  WHERE {} COLLATE NOCASE\n",
        "  LIMIT {}'''}\n",
        "  # по словам\n",
        "  for nn, ques in enumerate(conds):\n",
        "    for cond in ques:\n",
        "      #все условия для одного слова\n",
        "      if re.match('[A-Z]+', cond):\n",
        "          \n",
        "          que.append('{} = \"{}\"'.format(pos_tr[nn], cond))\n",
        "      elif re.match(r'\".+\"', cond):\n",
        "          que.append('(({} = {}) '.format(word_tr[nn], cond) + 'OR ({} = {}) '.format(word_tr[nn], cond.lower()) + 'OR ({} = {}))'.format(word_tr[nn], cond.title()))\n",
        "          #que.append('{} = {}'.format(word_tr[nn], cond))\n",
        "      else:\n",
        "          que.append('{} = \"{}\"'.format(lemma_tr[nn], morph.parse(cond)[0].normal_form))\n",
        "  big_que = ' AND '.join(que)\n",
        "  ask = ask[len(conds)].format(big_que, limit)\n",
        "  cur.execute(ask)\n",
        "  done = set(cur.fetchall())\n",
        "  result = []\n",
        "  for res in list(done):\n",
        "    dd = dict()\n",
        "    dd['pattern'] = ' '.join(list(filter(lambda x: str(x).isalpha(), res)))\n",
        "    dd['id_sent'] = res[1]\n",
        "    dd['id_text'] = res[0]\n",
        "    dd['id_word'] = res[2]\n",
        "    if len(res) > 4:\n",
        "      dd['last_word_id'] = res[-2]\n",
        "    result.append(dd)\n",
        "  return result"
      ],
      "metadata": {
        "id": "o_D6H4_yH9Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_query(\"ADP NOUN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CE4mwW9arRX",
        "outputId": "4ecf666f-5a0c-429d-eea3-d08fda93ed0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'pattern': 'в работе',\n",
              "  'id_sent': 9,\n",
              "  'id_text': 0,\n",
              "  'id_word': 1,\n",
              "  'last_word_id': 2},\n",
              " {'pattern': 'в зависимости',\n",
              "  'id_sent': 1,\n",
              "  'id_text': 0,\n",
              "  'id_word': 9,\n",
              "  'last_word_id': 10},\n",
              " {'pattern': 'с использованием',\n",
              "  'id_sent': 2,\n",
              "  'id_text': 0,\n",
              "  'id_word': 8,\n",
              "  'last_word_id': 9},\n",
              " {'pattern': 'с адресатом',\n",
              "  'id_sent': 2,\n",
              "  'id_text': 0,\n",
              "  'id_word': 15,\n",
              "  'last_word_id': 16},\n",
              " {'pattern': 'от пола',\n",
              "  'id_sent': 1,\n",
              "  'id_text': 0,\n",
              "  'id_word': 11,\n",
              "  'last_word_id': 12},\n",
              " {'pattern': 'с неаргументом',\n",
              "  'id_sent': 0,\n",
              "  'id_text': 0,\n",
              "  'id_word': 12,\n",
              "  'last_word_id': 13}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS big_words\n",
        "(id_text int, id_sent int, id_word int, word text, lemma text, pos text, id_word_right int, word_right text,\n",
        "lemma_right text, pos_right text, id_word_rright int, word_rright text, lemma_rright text, pos_rright text)\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "jq5a1ZFQa_XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = '''SELECT * FROM words\n",
        "  JOIN words_right ON words_right.id_sent=words.id_sent AND words_right.id_text=words.id_text AND id_word_right = (id_word + 1)\n",
        "  JOIN words_rright ON words_rright.id_sent=words.id_sent AND words_rright.id_text=words.id_text AND id_word_rright = (id_word + 2)'''\n",
        "cur.execute(q)\n",
        "ll = cur.fetchall()"
      ],
      "metadata": {
        "id": "zRa5D0eQfjsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBPNKLFahKu9",
        "outputId": "24d37eaa-1f5a-40f2-fc23-66759aa9afc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,\n",
              " 0,\n",
              " 0,\n",
              " 'Настоящий',\n",
              " 'настоящий',\n",
              " 'ADJ',\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 'доклад',\n",
              " 'доклад',\n",
              " 'NOUN',\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 'посвящен',\n",
              " 'посвятить',\n",
              " 'VERB')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in ll:\n",
        "  cur.execute(\"\"\"INSERT INTO big_words\n",
        "                (id_text, id_sent, id_word, word, lemma, pos, \n",
        "                id_word_right, word_right, lemma_right, pos_right,\n",
        "                id_word_rright, word_rright, lemma_rright, pos_rright) \n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?,?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
        "              (*line[:6], *line[8:12], *line[14:]))\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "CwAxMo7mhQjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur.execute('''DROP TABLE words;''')\n",
        "cur.execute('''DROP TABLE words_right;''')\n",
        "cur.execute('''DROP TABLE words_rright;''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWWbHVJ8gIV_",
        "outputId": "90879668-0718-4f67-92f7-03d16eee3478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7f0b9a00d0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn.commit()"
      ],
      "metadata": {
        "id": "y-Li_qJIiq8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "FCoMQTAEisu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('youngtyp_smol.db')\n",
        "cur = conn.cursor()"
      ],
      "metadata": {
        "id": "zHDPLAuCrNFW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS texts\n",
        "(id_text int, text text)\n",
        "\"\"\")\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS meta\n",
        "(id_text int, author text, topic text, year int, affilation text) \n",
        "\"\"\")\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS sents \n",
        "(id_text int, id_sent int, sent text) \n",
        "\"\"\")\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS big_words\n",
        "(id_text int, id_sent int, id_word int, word text, lemma text, pos text, id_word_right int, word_right text,\n",
        "lemma_right text, pos_right text, id_word_rright int, word_rright text, lemma_rright text, pos_rright text)\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "QlJOOQbZrPs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur.execute(\"\"\"SELECT * FROM big_words\n",
        "LIMIT 105\"\"\")\n",
        "wrds = cur.fetchall()\n",
        "cur.execute(\"\"\"SELECT * FROM texts\n",
        "LIMIT 105\"\"\")\n",
        "thts = cur.fetchall()\n",
        "cur.execute(\"\"\"SELECT * FROM sents LIMIT 105\"\"\")\n",
        "snts = cur.fetchall()\n",
        "cur.execute(\"\"\"SELECT * FROM meta\n",
        "LIMIT 105\"\"\")\n",
        "mts = cur.fetchall()"
      ],
      "metadata": {
        "id": "LlYlGILJrWME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(wrds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq19ApjItN7E",
        "outputId": "09141f9c-141b-48f4-b153-5a803860a862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for kk in wrds:\n",
        "    cur.execute(\"\"\"INSERT INTO big_words (id_text, id_sent, id_word, word, lemma, pos, \n",
        "                id_word_right, word_right, lemma_right, pos_right,\n",
        "                id_word_rright, word_rright, lemma_rright, pos_rright)\n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?,?, ?, ?, ?, ?, ?, ?)\"\"\", kk)\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "JCdyRw2ur3ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ss in snts:\n",
        "    cur.execute(\"\"\"INSERT INTO sents\n",
        "                (id_text, id_sent, sent) \n",
        "                VALUES (?, ?, ?)\"\"\", ss)\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "wRxgLoXWswhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for mm in mts:\n",
        "    cur.execute(\"\"\"INSERT INTO meta\n",
        "                (id_text, author, topic, year, affilation) \n",
        "                VALUES (?, ?, ?, ?, ?)\"\"\", mm)\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "FowcWnrduJhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tt in thts:\n",
        "    cur.execute(\"\"\"INSERT INTO texts\n",
        "                (id_text, text) \n",
        "                VALUES (?, ?)\"\"\", tt)\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "QQD04yS2uWVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "tEJWX_umueM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUaoTRDfugJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}